
partner:fub a lod2:Partner;
    sysont:order "4"^^xsd:integer;
    lod2:previous partner:nuig;
    lod2:next partner:openlink;
    skos:broader pages:Consortium;
    foaf:based_near <http://dbpedia.org/resource/Berlin>;
    foaf:homepage <http://www.wiwiss.fu-berlin.de/en/institute/pwo/bizer/index.html>;
    rdfs:label "Freie Universität Berlin";
    lod2:content """
<p>The Web-based Systems Group at Freie Universität Berlin explores technical and economic questions concerning the development of global, decentralized information environments. Its current focus lies on the publication and interlinking of structured data on the Web using Semantic Web technologies.</p>
<p>The group has initialized several widely used open source software projects including D2RQ, D2R Server, RAP – RDF API for PHP, and NG4G – Named Graphs API for Jena. The group contributes to several open data publishing efforts including DBpedia and the W3C Linking-Open-Data project which aims at interlinking large numbers of data sources on the Web. The Web-based Systems Group is active within the World Wide Web Consortium where it has contributed to the SPARQL recommendation and participates in the Semantic Web Education and Outreach activity. The group maintains strong research ties with the Massachusetts Institute of Technology, Hewlett-Packard Labs, and the Open Archives Initiative.</p>""";
    lod2:abstract """Freie University Berlin will bring in expertise, tools and outreach capabilities to LOD2: (1) FUB has developed and maintains the Silk – Link Discovery Framework and Link Quality Assurance Workbench, which will be significantly extended and integrated into the LOD2 Stack. (2) FUB has developed D2R Server, the most widely used tool for publishing relational databases as Linked Data on the Web. D2R Server will be used for the domain complementation task in WP3 and will be included together with Pubby and Silk into the LOD2 Stack (WP6). (3) Within WP10 Training, Dissemination, community building, FUB will use its existing community building (initiator of W3C LOD) and outreach capabilities (Linked Data on the Web (LDOW) workshop series, Semantic Web Challenge competition series) to maximize the impact of LOD2.
"""    ;
    lod2:feedRelevantFor :Welcome .


project:D2R-Server a doap:Project;
    skos:broader pages:TechnologyStack;
    doap:homepage <http://www4.wiwiss.fu-berlin.de/bizer/d2r-server/>;
    lod2:content """
<p>D2R Server is a tool for publishing the content of relational databases
  on the <a href="http://www.w3.org/2001/sw/">Semantic Web</a>, a global
  information space consisting of
  <a href="http://www.w3.org/DesignIssues/LinkedData.html">linked data</a>.</p>
<p>Data on the Semantic Web is modelled and represented in
  <a href="http://en.wikipedia.org/wiki/Resource_Description_Framework">RDF</a>.
  D2R Server uses a customizable
  <a href="http://www4.wiwiss.fu-berlin.de/bizer/d2rq/spec/#specification">D2RQ mapping</a>
  to map database content into this format, and allows the RDF data to be
  <em>browsed</em> and <em>searched</em> &#8211; the two main access paradigms
  to the Semantic Web.</p>
<p>D2R Server's <strong>Linked Data interface</strong> makes RDF descriptions of individual resources available over the HTTP protocol. An RDF description can be retrieved simply by accessing the resource's URI over the Web. Using a Semantic Web browser like <a href="http://www.w3.org/2005/ajar/tab">Tabulator</a> (<a href="http://www.w3.org/2006/Talks/1019-tab-tbl/">slides</a>) or <a href="http://www4.wiwiss.fu-berlin.de/bizer/ng4j/disco/">Disco</a>, you can follow links from one resource to the next, surfing the Web of Data.</p>
<p>The <strong>SPARQL interface</strong> enables applications to search and query the database using the <a href="http://www.w3.org/TR/rdf-sparql-query/">SPARQL</a> query language over the SPARQL protocol.</p>
<p>A traditional <strong>HTML interface</strong> offers access to the familiar Web browsers.</p>
<p align="center"><img src="http://www4.wiwiss.fu-berlin.de/bizer/d2r-server/images/architecture.png" alt="D2R Server architecture diagram" /></p>
<p>Requests from the Web are rewritten into SQL queries via the mapping. This on-the-fly translation allows publishing of RDF from large live databases and eliminates the need for replicating the data into a dedicated RDF triple store.</p>
<p><strong>Read more</strong> about the interfaces offered by D2R Server, including example HTTP requests and responses, in the Technical Note <a href="publishing/">Publishing Databases on the Semantic Web</a>.</p>
""";
    lod2:abstract """D2R Server is a tool for publishing relational databases on the Semantic Web. It enables RDF and HTML browsers to navigate the content of the database, and allows applications to query the database using the SPARQL query language.""";
    lod2:partner partner:fub;
    rdfs:label "D2R Server";
    lod2:feedRelevantFor :Welcome .


project:Silk a doap:Project;
    skos:broader pages:TechnologyStack;
    doap:homepage <http://www4.wiwiss.fu-berlin.de/bizer/silk/>;
    lod2:content """
<P>The Web of Data is built upon two simple ideas: First, to employ the RDF
data model to publish structured data on the Web. Second, to set explicit <a href="http://www4.wiwiss.fu-berlin.de/bizer/pub/LinkedDataTutorial/#links">RDF links</a>
between data items within different data sources. Background information about the Web of Data is found at the wiki pages of the <a href="http://esw.w3.org/topic/SweoIG/TaskForces/CommunityProjects/LinkingOpenData">W3C Linking Open Data community effort</a>,
    in the overview article <a href="http://tomheath.com/papers/bizer-heath-berners-lee-ijswis-linked-data.pdf">Linked Data - The Story So Far</a>

and in the tutorial on <a href="http://www4.wiwiss.fu-berlin.de/bizer/pub/LinkedDataTutorial/">How to publish Linked Data on the Web</a>. 
</P>
<p>The <em>Silk Link Discovery Framework</em> supports data publishers in accomplishing the
second task. Using the declarative <em>Silk - Link Specification Language</em> (Silk-LSL), developers can specify which types of
RDF links should be discovered between data sources as well as which conditions data items must
fulfill in order to be interlinked. These link conditions may combine various similarity
metrics and can take the graph around a data item into account, which is addressed
using an RDF path language. Silk accesses the data sources that should be interlinked via the SPARQL protocol and can thus be used against local as well as remote SPARQL endpoints. </p>
<p>The main features of the Silk link discovery engine are:</p>
<ul>
  <li>Open source link discovery framework, running on all major platforms</li>

  <li>Support of RDF link generation (owl:sameAs links as well as other types)</li>
  <li>Flexible, declarative language for specifying link conditions</li>
  <li>Employment in distributed environments (by accessing local and remote SPARQL endpoints)</li>
  <li>Usable in situations where terms from different vocabularies are mixed and where no consistent RDFS or OWL schemata exist</li>
  <li>Scalability and high performance through efficient data handling (speedup factor of 20 compared to Silk 0.2):
    <ul>
        <li>Reduction of network load by caching and reusing of SPARQL result sets</li>

        <li>Multi-threaded computation of the data item comparisons (3 million comparisons per minute on a Core2 Duo)</li>
        <li>Optional blocking of data items</li>
    </ul>
  </li>
</ul>

<p>Silk is implemented in Scala running on the Java Virtual Machine.     In order to run Silk, developers need to:</p>
<ol>
  <li>Have SPARQL access to the datasets that should be interlinked.</li>

  <li>Write a link specification as described in the <a href="http://www4.wiwiss.fu-berlin.de/bizer/silk/spec/">Silk - User Manual</a>. </li>
  <li>Install the Silk framework as described in the <a href="http://www4.wiwiss.fu-berlin.de/bizer/silk/spec/index.htm#usage">Installation and Usage</a> section of the manual.</li>
</ol>

""";
    lod2:abstract """The Silk Linking Framework supports data publishers in setting explicit RDF links between data items within different data sources. Using the declarative Silk - Link Specification Language (Silk-LSL), developers can specify which types of RDF links should be discovered between data sources as well as which conditions data items must fulfil in order to be interlinked. These link conditions may combine various similarity metrics and can take the graph around a data item into account, which is addressed using an RDF path language.""";
    lod2:partner partner:fub;
    rdfs:label "Silk Framework";
    lod2:feedRelevantFor :Welcome .



project:WIQA a doap:Project;
    skos:broader pages:TechnologyStack;
    doap:homepage <http://www4.wiwiss.fu-berlin.de/bizer/wiqa/>;
    lod2:content """
<p>The <strong>WIQA - Information Quality Assessment Framework</strong> is a set of software components for filtering information from the Web using a wide range of different filtering policies.</p>
<p>The framework has been designed to fulfill the following requirements: </p>
<ul>
  <li><strong> Flexible Representation of Information together with Quality-Related Meta-information.</strong> Information quality assessment may rely on a wide range of different quality indicators. Which quality indicators are relevant depends on the application domain and the quality dimensions to be assessed. Important quality indicators in the context of web-based information systems are provenance information, ratings, and background information about information providers. The WIQA framework uses Named Graphs  [<a href="http://www4.wiwiss.fu-berlin.de/bizer/wiqa/#CaBiHaSt04">CaBiHaSt05</a>] as a flexible data model for representing information together with quality related meta-information.</li>
<li><strong>Support for different Information Filtering Policies.</strong> The relevancy of different quality dimensions and the metrics used to assess these dimensions depend on the application domain, the quality indicators available, the task at hand and the subjective preferences of the information consumer. Therefore, information consumers use a wide range of different information filtering policies in different situations. The WIQA framework allows different policies to be employed for filtering information. Policies are expressed using a declarative policy language and can combine context-, content- and rating-based assessment metrics.</li>
<li><strong>Explaining Filtering Decisions.</strong> The accuracy of assessment results is often uncertain due to the limited availability of quality indicators and the uncertain quality of the quality indicators themself. Therefore, the final subjective decision of an information consumer whether to trust or distrust assessment results depends on his understanding of the quality indicators and the assessment metrics that have been used in the assessment process. In order to support information consumers in their trust decision, the WIQA framework can generate detailed explanations about filtering decisions.</li>
</ul>
""";
    lod2:abstract """The Web Information Quality Assessment Framework is a set of software components that empowers information consumers to employ a wide range of different information quality assessment policies to filter information from the Web. Information providers on the Web have different levels of knowledge, different views of the world and different intensions. Thus, provided information may be wrong, biased, inconsistent or outdated. Before information from the Web is used to accomplish a specific task, its quality should be assessed according to task-specific criteria.""";
    lod2:partner partner:fub;
    rdfs:label "WIQA";
    lod2:feedRelevantFor :Welcome .


project:SemMF a doap:Project;
    skos:broader pages:TechnologyStack;
    doap:homepage <http://semmf.ag-nbi.de/>;
    lod2:content """
<p>SemMF is a flexible framework for calculating semantic similarity between objects that are represented as arbitrary RDF graphs. The framework allows taxonomic and non-taxonomic concept matching techniques to be applied to selected object properties. Moreover, new concept matchers are easily integrated into SemMF by implementing a simple interface, thus making it applicable in a wide range of different use case scenarios. </p>

<p><strong>Framework Architecture</strong>: he Matching Engine takes as input a query object  and a collection of resource objects  to be matched against the query object. Both are represented in RDF and may utilize different schema vocabularies. If they use concepts from a common taxonomy, an RDFS or OWL representation of this taxonomy has to be provided.</p>
<p>SemMF Engine  is implemented in Java utilizing <a href="http://jena.sourceforge.net/">Jena2 Semantic Web Framework</a> for accessing and querying of resource and query graphs as well as the underlying taxonomies.</p>
<p><img src="http://semmf.ag-nbi.de/doc/img/semmf_overview.jpg"></p>

<p><strong>Matching Description:</strong> In most cases not every object property is relevant for the similarity computation. For example, an object representing a certain product may contain manufacturer's phone number which may be irrelevant for comparing product's characteristics with customer's preferences (query object). Thus, each relevant property in the query RDF graph must be explicitly specified and mapped to the semantically corresponding property (i.e. holding the same kind of information, e.g. price information) in a resource RDF graph. Each mapping is assigned a <a href="http://semmf.ag-nbi.de/doc/matchers.html">concept matcher</a> implementing a certain matching technique. </p>
<p>In a <a href="http://semmf.ag-nbi.de/doc/creatingMD.html">matching description</a> the importance of each object property can be specified by assigning it a certain <em>weight </em>. Moreover, properties to be matched can be grouped into thematic clusters, for example all properties describing  technical specification of a product. The property clustering enables to sort the matching result by cluster similarities. The matching description is represented in RDF using <a href="http://semmf.ag-nbi.de/vocabulary/1.1/semmf.rdfs">SemMF vocabulary</a> provided with the framework. </p>

<p><strong>Matching Process:</strong> Inside each thematic cluster the Engine calculates the similarity between each query property and the corresponding resource property. These similarities are multiplied by the indicated weights and summed up yielding the cluster similarity. All cluster similarities, in turn, multiplied by the specified cluster weights yield the object similarity. </p>
<p>However, if for a given query property value there is more than one semantically corresponding resource property value (e.g. a product may be available in different colors) the Engine chooses the one with the highest similarity.</p>

<p><strong>Matching Result:</strong>: The output of the Matching Engine is a ranking of objects by their similarity values. The Engine also provides a <a href="http://semmf.ag-nbi.de/doc/traversingMatchingResult.html">detailed description of the matching process</a> (i.e. object property values, similarity values for all clusters and for each single object property within a cluster, associated weights, etc.) which can be used to generate explanations for the calculated object similarity. </p>
""";
    lod2:abstract """SemMF is a flexible framework for calculating semantic similarity between objects that are represented as arbitrary RDF graphs. The framework allows taxonomic and non-taxonomic concept matching techniques to be applied to selected object properties. Moreover, new concept matchers are easily integrated into SemMF by implementing a simple interface, thus making it applicable in a wide range of different use case scenarios""";
    lod2:partner partner:fub;
    rdfs:label "SemMF";
    lod2:feedRelevantFor :Welcome .

